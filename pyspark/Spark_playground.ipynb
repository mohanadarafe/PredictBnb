{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "quarterly-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, os, sys\n",
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, StringIndexer\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sweet-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a spark session.\n",
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark SQL basic example\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nearby-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = init_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-helen",
   "metadata": {},
   "source": [
    "# Load data from file into spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spoken-purple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+-------------------+--------+\n",
      "|      Id|               Title|                Body|                Tags|       CreationDate|       Y|\n",
      "+--------+--------------------+--------------------+--------------------+-------------------+--------+\n",
      "|34552656|Java: Repeat Task...|<p>I'm already fa...|      <java><repeat>|2016-01-01 00:21:59|LQ_CLOSE|\n",
      "|34553034|Why are Java Opti...|<p>I'd like to un...|    <java><optional>|2016-01-01 02:03:20|      HQ|\n",
      "|34553174|Text Overlay Imag...|<p>I am attemptin...|<javascript><imag...|2016-01-01 02:48:24|      HQ|\n",
      "|34553318|Why ternary opera...|<p>The question i...|<swift><operators...|2016-01-01 03:30:17|      HQ|\n",
      "|34553755|hide/show fab wit...|<p>I'm using cust...|<android><materia...|2016-01-01 05:21:48|      HQ|\n",
      "+--------+--------------------+--------------------+--------------------+-------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename_train = \"../dataset/train.csv\"\n",
    "filename_test = \"../dataset/valid.csv\"\n",
    "\n",
    "train_rdd = spark.read.csv(filename_train, header=True, multiLine=True, inferSchema=True, escape='\"', quote='\"')\n",
    "test_rdd = spark.read.csv(filename_test, header=True, multiLine=True, inferSchema=True, escape='\"', quote='\"')\n",
    "train_rdd.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "superb-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = train_rdd.rdd \\\n",
    "    .map(lambda x: (x[\"Title\"]+\" \"+x[\"Body\"], x[\"Y\"])) \\\n",
    "    .toDF([\"Question\", \"Output\"])# change to collect()\n",
    "\n",
    "testing = test_rdd.rdd \\\n",
    "    .map(lambda x: (x[\"Title\"]+\" \"+x[\"Body\"], x[\"Y\"])) \\\n",
    "    .toDF([\"Question\", \"Output\"]) # change to collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-service",
   "metadata": {},
   "source": [
    "# Prepare pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "concrete-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stop_word_remover(input_col_name, stopwords):\n",
    "    return StopWordsRemover(inputCol=input_col_name, outputCol=\"filtered\").setStopWords(stopwords)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "stupid-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HEURISTIC 1 - Tokenize the words\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"Question\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "\n",
    "# HEURISTIC 2 - Remove the stopwords\n",
    "add_stopwords = [\"the\", \"a\", \"be\", \"of\", \"and\", \"to\", \"why\"] \n",
    "stopwordsRemover = get_stop_word_remover(\"words\", add_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "forward-lesbian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bag_of_word_model(features_col_name, label_col_name):\n",
    "    countVectors = CountVectorizer(inputCol=features_col_name, outputCol=\"features\")\n",
    "    indexed_features = StringIndexer(inputCol = label_col_name, outputCol = \"label\")\n",
    "    return countVectors, indexed_features\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "western-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "countVectors_h1, indexed_features_h1 = get_bag_of_word_model(\"words\", \"Output\")\n",
    "countVectors_h2, indexed_features_h2 = get_bag_of_word_model(\"filtered\", \"Output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "green-console",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline(*args):\n",
    "    return Pipeline(stages=[*args])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "united-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_h1 = get_pipeline(regexTokenizer, countVectors_h1, indexed_features_h1)\n",
    "pipeline_h2 = get_pipeline(regexTokenizer, stopwordsRemover, countVectors_h2, indexed_features_h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-combining",
   "metadata": {},
   "source": [
    "# Process data through Pipeline train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "soviet-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline_model(pipeline, data):\n",
    "    \"\"\" We should use the same pipeline model on training and testing \"\"\"\n",
    "    return pipeline.fit(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-publisher",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "different-drive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------------------+-----+\n",
      "|            Question|  Output|               words|            features|label|\n",
      "+--------------------+--------+--------------------+--------------------+-----+\n",
      "|Java: Repeat Task...|LQ_CLOSE|[java, repeat, ta...|(201488,[0,1,2,3,...|  1.0|\n",
      "|Why are Java Opti...|      HQ|[why, are, java, ...|(201488,[0,1,4,7,...|  0.0|\n",
      "|Text Overlay Imag...|      HQ|[text, overlay, i...|(201488,[0,1,2,3,...|  0.0|\n",
      "|Why ternary opera...|      HQ|[why, ternary, op...|(201488,[0,1,2,3,...|  0.0|\n",
      "|hide/show fab wit...|      HQ|[hide, show, fab,...|(201488,[0,1,4,5,...|  0.0|\n",
      "|Accessing pointer...|LQ_CLOSE|[accessing, point...|(201488,[0,1,2,3,...|  1.0|\n",
      "|How To Disable 2n...| LQ_EDIT|[how, to, disable...|(201488,[1,4,8,15...|  2.0|\n",
      "|Resizing containe...| LQ_EDIT|[resizing, contai...|(201488,[1,2,3,4,...|  2.0|\n",
      "|Changing Theme in...|      HQ|[changing, theme,...|(201488,[0,1,2,3,...|  0.0|\n",
      "|TextBox Value Dis...| LQ_EDIT|[textbox, value, ...|(201488,[1,6,7,8,...|  2.0|\n",
      "|MongoDB Failing t...|      HQ|[mongodb, failing...|(201488,[0,1,3,4,...|  0.0|\n",
      "|What's the best w...|LQ_CLOSE|[what, s, the, be...|(201488,[0,1,2,3,...|  1.0|\n",
      "|ios/objective-c/x...| LQ_EDIT|[ios, objective, ...|(201488,[1,2,4,5,...|  2.0|\n",
      "|output FILE ,is t...| LQ_EDIT|[output, file, is...|(201488,[1,2,3,4,...|  2.0|\n",
      "|Pod install displ...|      HQ|[pod, install, di...|(201488,[0,2,3,4,...|  0.0|\n",
      "|Haskell Stack Ghc...|      HQ|[haskell, stack, ...|(201488,[0,1,2,3,...|  0.0|\n",
      "|Why does the reve...|      HQ|[why, does, the, ...|(201488,[0,1,2,3,...|  0.0|\n",
      "|eb deploy does no...|      HQ|[eb, deploy, does...|(201488,[0,1,2,3,...|  0.0|\n",
      "|How to create a f...| LQ_EDIT|[how, to, create,...|(201488,[1,2,3,4,...|  2.0|\n",
      "|bluebird.js vs bl...|      HQ|[bluebird, js, vs...|(201488,[0,1,2,4,...|  0.0|\n",
      "+--------------------+--------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_pipeline = pipeline_h1.fit(training)\n",
    "# model_pipeline = process_data_in_pipeline(pipeline_h1, training)\n",
    "data_h1_train  = model_pipeline.transform(training) #what does the transform do?\n",
    "data_h1_train.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-secretary",
   "metadata": {},
   "source": [
    "**Vocabulary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ceramic-disabled",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1293400': 1, 'mypass': 5, 'connected': 433, 'few': 902, 'input': 9663, 'online': 599, '389999': 1, 'travel': 74, '836400': 1, 'those': 1212, 'still': 2194, 'thread1': 26, 'hope': 513, 'recognize': 120, 'parentheses': 89, 'arguments': 696, 'persist': 74, '2bxhsys2c47eyjfhpmroalpxz5suigeubqu7hjuvfvwpoa0xri3iljvhq5qgbwtwpe1x0': 2, 'pabu': 1, 'some': 8532}\n"
     ]
    }
   ],
   "source": [
    "# vocabulary frequency without using the countVectorizer helper column that we generated\n",
    "counts = data_h1_train.select(f.explode('words').alias('col')).groupBy('col').count().take(20)\n",
    "print({row['col']: row['count'] for row in counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "subtle-restoration",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-7b4ae0958939>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# using the countVectorizer helper column that we generated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_h1_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'words'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vectors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# using the countVectorizer helper column that we generated\n",
    "# https://stackoverflow.com/questions/50255356/pyspark-countvectorizer-and-word-frequency-in-a-corpus\n",
    "counts = data_h1_train.select('words').take(20)\n",
    "print(dict(zip(vocabulary, counts[0]['words'].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "english-control",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------------------+-----+\n",
      "|            Question|  Output|               words|            features|label|\n",
      "+--------------------+--------+--------------------+--------------------+-----+\n",
      "|How to get all th...| LQ_EDIT|[how, to, get, al...|(86590,[1,2,4,6,9...|  2.0|\n",
      "|Retrieve all exce...| LQ_EDIT|[retrieve, all, e...|(86590,[1,2,7,9,1...|  2.0|\n",
      "|Pandas: read_html...|      HQ|[pandas, read_htm...|(86590,[0,1,2,3,4...|  0.0|\n",
      "|Reader Always gim...| LQ_EDIT|[reader, always, ...|(86590,[1,2,4,5,7...|  2.0|\n",
      "|php rearrange arr...| LQ_EDIT|[php, rearrange, ...|(86590,[1,2,4,5,6...|  2.0|\n",
      "|How do I make a c...|LQ_CLOSE|[how, do, i, make...|(86590,[0,1,2,3,4...|  1.0|\n",
      "|how can i create ...| LQ_EDIT|[how, can, i, cre...|(86590,[1,5,6,9,1...|  2.0|\n",
      "|Re-exporting ES6 ...|      HQ|[re, exporting, e...|(86590,[0,1,2,3,4...|  0.0|\n",
      "|Fetch API with Co...|      HQ|[fetch, api, with...|(86590,[0,1,2,4,5...|  0.0|\n",
      "|Print list conten...|LQ_CLOSE|[print, list, con...|(86590,[0,1,2,3,4...|  1.0|\n",
      "|c# - List all pri...| LQ_EDIT|[c, list, all, pr...|(86590,[1,2,3,4,5...|  2.0|\n",
      "|Angular2 exceptio...|      HQ|[angular2, except...|(86590,[0,3,11,21...|  0.0|\n",
      "|Form Validation p...|LQ_CLOSE|[form, validation...|(86590,[0,1,2,4,5...|  1.0|\n",
      "|Most Pythonic way...|      HQ|[most, pythonic, ...|(86590,[0,1,2,3,4...|  0.0|\n",
      "|Gulp error intern...|      HQ|[gulp, error, int...|(86590,[0,1,2,4,9...|  0.0|\n",
      "|Filter Name with ...| LQ_EDIT|[filter, name, wi...|(86590,[1,2,3,4,6...|  2.0|\n",
      "|Django ImageField...|      HQ|[django, imagefie...|(86590,[0,1,2,3,4...|  0.0|\n",
      "|Compiling SASS in...|LQ_CLOSE|[compiling, sass,...|(86590,[0,1,4,5,6...|  1.0|\n",
      "|to get or set the...| LQ_EDIT|[to, get, or, set...|(86590,[1,2,3,4,5...|  2.0|\n",
      "|i am new to pythn...| LQ_EDIT|[i, am, new, to, ...|(86590,[1,3,4,7,9...|  2.0|\n",
      "+--------------------+--------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_h1_test = process_data_in_pipeline(pipeline_h1, testing)\n",
    "data_h1_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "satisfactory-station",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------------------+-----+\n",
      "|            Question|  Output|               words|            features|label|\n",
      "+--------------------+--------+--------------------+--------------------+-----+\n",
      "|How to get all th...| LQ_EDIT|[how, to, get, al...|(201488,[1,2,4,6,...|  2.0|\n",
      "|Retrieve all exce...| LQ_EDIT|[retrieve, all, e...|(201488,[1,2,7,8,...|  2.0|\n",
      "|Pandas: read_html...|      HQ|[pandas, read_htm...|(201488,[0,1,2,3,...|  0.0|\n",
      "|Reader Always gim...| LQ_EDIT|[reader, always, ...|(201488,[1,2,4,5,...|  2.0|\n",
      "|php rearrange arr...| LQ_EDIT|[php, rearrange, ...|(201488,[1,2,4,5,...|  2.0|\n",
      "|How do I make a c...|LQ_CLOSE|[how, do, i, make...|(201488,[0,1,2,3,...|  1.0|\n",
      "|how can i create ...| LQ_EDIT|[how, can, i, cre...|(201488,[1,5,6,8,...|  2.0|\n",
      "|Re-exporting ES6 ...|      HQ|[re, exporting, e...|(201488,[0,1,2,3,...|  0.0|\n",
      "|Fetch API with Co...|      HQ|[fetch, api, with...|(201488,[0,1,2,4,...|  0.0|\n",
      "|Print list conten...|LQ_CLOSE|[print, list, con...|(201488,[0,1,2,3,...|  1.0|\n",
      "|c# - List all pri...| LQ_EDIT|[c, list, all, pr...|(201488,[1,2,3,4,...|  2.0|\n",
      "|Angular2 exceptio...|      HQ|[angular2, except...|(201488,[0,3,11,2...|  0.0|\n",
      "|Form Validation p...|LQ_CLOSE|[form, validation...|(201488,[0,1,2,4,...|  1.0|\n",
      "|Most Pythonic way...|      HQ|[most, pythonic, ...|(201488,[0,1,2,3,...|  0.0|\n",
      "|Gulp error intern...|      HQ|[gulp, error, int...|(201488,[0,1,2,4,...|  0.0|\n",
      "|Filter Name with ...| LQ_EDIT|[filter, name, wi...|(201488,[1,2,3,4,...|  2.0|\n",
      "|Django ImageField...|      HQ|[django, imagefie...|(201488,[0,1,2,3,...|  0.0|\n",
      "|Compiling SASS in...|LQ_CLOSE|[compiling, sass,...|(201488,[0,1,4,5,...|  1.0|\n",
      "|to get or set the...| LQ_EDIT|[to, get, or, set...|(201488,[1,2,3,4,...|  2.0|\n",
      "|i am new to pythn...| LQ_EDIT|[i, am, new, to, ...|(201488,[1,3,4,7,...|  2.0|\n",
      "+--------------------+--------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_h1_test  = model_pipeline.transform(testing)\n",
    "data_h1_test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-symbol",
   "metadata": {},
   "source": [
    "# Split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "awful-tucson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data, distribution):\n",
    "    return data.randomSplit([distribution, 1-distribution], seed = 1234)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "intense-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_h1, validate_h1 = split_dataset(data_h1_train, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "adjusted-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1,test2 = split_dataset(data_h1_test, 0.7) # just for testing purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-tower",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning | is this doing anything? we are not using any data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "varying-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_smoothing_values(target_col, prediction_col):\n",
    "    # Create grid to find best smoothing\n",
    "    nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "    paramGrid = ParamGridBuilder().addGrid(nb.smoothing, [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]).build()\n",
    "#     cvEvaluator = BinaryClassificationEvaluator(rawPredictionCol=prediction_col)\n",
    "    cvEvaluator = MulticlassClassificationEvaluator(labelCol=target_col, predictionCol=prediction_col)\n",
    "\n",
    "    # Cross-validate all smoothing values\n",
    "    cv = CrossValidator(estimator=nb, estimatorParamMaps=paramGrid, evaluator=cvEvaluator)\n",
    "    return cv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "automated-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = get_best_smoothing_values(\"label\", \"prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-assets",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "caring-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel = cv.fit(train_h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-hindu",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "balanced-concentrate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation set\n",
    "cvPredictions = cvModel.transform(validate_h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "vulnerable-operator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cvPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "satisfied-bikini",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  2.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  2.0|       2.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       0.0|\n",
      "|  1.0|       1.0|\n",
      "|  0.0|       1.0|\n",
      "|  2.0|       2.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       1.0|\n",
      "+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cvPredictions.select(\"label\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "built-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvPredictions_test = cvModel.transform(data_h1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "micro-access",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  2.0|       2.0|\n",
      "|  2.0|       2.0|\n",
      "|  0.0|       0.0|\n",
      "|  2.0|       2.0|\n",
      "|  2.0|       2.0|\n",
      "|  1.0|       1.0|\n",
      "|  2.0|       2.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       0.0|\n",
      "|  2.0|       1.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       0.0|\n",
      "|  0.0|       1.0|\n",
      "|  0.0|       0.0|\n",
      "|  2.0|       2.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       0.0|\n",
      "|  2.0|       2.0|\n",
      "|  2.0|       2.0|\n",
      "+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cvPredictions_test.select(\"label\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-demographic",
   "metadata": {},
   "source": [
    "# Evaluate Performance of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "organic-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(target_col, prediction_col, predictionAndTarget):\n",
    "#     evaluator = BinaryClassificationEvaluator(rawPredictionCol=prediction_col)\n",
    "    evaluatorMulti = MulticlassClassificationEvaluator(labelCol=target_col, predictionCol=prediction_col)\n",
    "#     accuracy = evaluatorMulti.evaluate(predictions)\n",
    "    # Get metrics\n",
    "    acc = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"accuracy\"})\n",
    "    f1 = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"f1\"})\n",
    "    weightedPrecision = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"weightedPrecision\"})\n",
    "    weightedRecall = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"weightedRecall\"})\n",
    "#     auc = evaluator.evaluate(predictionAndTarget)\n",
    "    print (\"Model Accuracy: \", acc)\n",
    "    print (\"Model f1-score: \", f1)\n",
    "    print (\"Model weightedPrecision: \", weightedPrecision)\n",
    "    print (\"Model weightedRecall: \", weightedRecall)\n",
    "#     return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "identical-stake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.7653008490217793\n",
      "Model f1-score:  0.7675841714238029\n",
      "Model weightedPrecision:  0.7901628512971111\n",
      "Model weightedRecall:  0.7653008490217792\n"
     ]
    }
   ],
   "source": [
    "# Validation Dataset\n",
    "evaluate_model(\"label\", \"prediction\", cvPredictions.select(\"label\",\"prediction\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "floppy-slave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.7633333333333333\n",
      "Model f1-score:  0.7649182102284617\n",
      "Model weightedPrecision:  0.7866094786891012\n",
      "Model weightedRecall:  0.7633333333333333\n"
     ]
    }
   ],
   "source": [
    "# testing dataset\n",
    "evaluate_model(\"label\", \"prediction\", cvPredictions_test.select(\"label\",\"prediction\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-academy",
   "metadata": {},
   "source": [
    "# Creating one big iteration for all the pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "amended-packing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######Pipeline 1#######\n",
      "**Creating pipeline model**\n",
      "**Transforming training data**\n",
      "**Transforming testing data**\n",
      "**Hyperparameter tuning**\n",
      "**Training the model**\n",
      "**predicting on testing dataset**\n",
      "**Measuring performance**\n",
      "Model Accuracy:  0.7726\n",
      "Model f1-score:  0.7746909975733439\n",
      "Model weightedPrecision:  0.7939332260574594\n",
      "Model weightedRecall:  0.7726\n",
      "#######Pipeline 2#######\n",
      "**Creating pipeline model**\n",
      "**Transforming training data**\n",
      "**Transforming testing data**\n",
      "**Hyperparameter tuning**\n",
      "**Training the model**\n",
      "**predicting on testing dataset**\n",
      "**Measuring performance**\n",
      "Model Accuracy:  0.7788666666666667\n",
      "Model f1-score:  0.7811193586213604\n",
      "Model weightedPrecision:  0.7985977934238272\n",
      "Model weightedRecall:  0.7788666666666667\n",
      "CPU times: user 1.24 s, sys: 237 ms, total: 1.48 s\n",
      "Wall time: 4min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for pipeline, pipe_name in zip([pipeline_h1, pipeline_h2],[\"Pipeline 1\",\"Pipeline 2\"]):\n",
    "    print(\"#######\"+ pipe_name + \"#######\")\n",
    "    print(\"**\"+ \"Creating pipeline model\" + \"**\") \n",
    "    model_pipeline = get_pipeline_model(pipeline, training)\n",
    "    print(\"**\"+ \"Transforming training data\" + \"**\") \n",
    "    data_train  = model_pipeline.transform(training)\n",
    "    print(\"**\"+ \"Transforming testing data\" + \"**\") \n",
    "    data_test  = model_pipeline.transform(testing)\n",
    "    print(\"**\"+ \"Hyperparameter tuning\" + \"**\") \n",
    "    cv = get_best_smoothing_values(\"label\", \"prediction\")\n",
    "    print(\"**\"+ \"Training the model\" + \"**\") \n",
    "    cvModel = cv.fit(data_train)\n",
    "    print(\"**\"+ \"predicting on testing dataset\" + \"**\") \n",
    "    cvPredictions = cvModel.transform(data_test)\n",
    "    print(\"**\"+ \"Measuring performance\" + \"**\")\n",
    "    evaluate_model(\"label\", \"prediction\", cvPredictions.select(\"label\",\"prediction\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-korean",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
