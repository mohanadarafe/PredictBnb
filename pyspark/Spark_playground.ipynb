{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lyric-chancellor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, os, sys\n",
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, StringIndexer\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "# import pyspark.sql.functions as f\n",
    "# from pyspark.sql.functions import udf\n",
    "# from nltk.stem.snowball import SnowballStemmer\n",
    "# from pyspark.sql.types import ArrayType, StringType\n",
    "from time import time\n",
    "from datetime import timedelta,datetime\n",
    "from sys import argv\n",
    "import psutil as psu\n",
    "from utility import *\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "contained-groove",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a spark session.\n",
    "@metrics\n",
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark SQL basic example\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "juvenile-proposal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Memory in use: 5.97GiB\n",
      "Disk in use: 58.40%\n",
      "CPU in use: 15.50%\n",
      "Disk free: 7.41GiB\n",
      "Time on CPU: 1:14:59.270000\n",
      "\n",
      "\n",
      " AFTER CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Memory in use: 5.97GiB\n",
      "Disk in use: 58.40%\n",
      "CPU in use: 0.00%\n",
      "Disk free: 7.41GiB\n",
      "Time on CPU: 1:14:59.270000\n",
      "Execution Time: 0.003654956817626953\n"
     ]
    }
   ],
   "source": [
    "spark = init_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-quest",
   "metadata": {},
   "source": [
    "# Load data from file into spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "multiple-hollywood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+-------------------+--------+\n",
      "|      Id|               Title|                Body|                Tags|       CreationDate|       Y|\n",
      "+--------+--------------------+--------------------+--------------------+-------------------+--------+\n",
      "|34552656|Java: Repeat Task...|<p>I'm already fa...|      <java><repeat>|2016-01-01 00:21:59|LQ_CLOSE|\n",
      "|34553034|Why are Java Opti...|<p>I'd like to un...|    <java><optional>|2016-01-01 02:03:20|      HQ|\n",
      "|34553174|Text Overlay Imag...|<p>I am attemptin...|<javascript><imag...|2016-01-01 02:48:24|      HQ|\n",
      "|34553318|Why ternary opera...|<p>The question i...|<swift><operators...|2016-01-01 03:30:17|      HQ|\n",
      "|34553755|hide/show fab wit...|<p>I'm using cust...|<android><materia...|2016-01-01 05:21:48|      HQ|\n",
      "+--------+--------------------+--------------------+--------------------+-------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename_train = \"../dataset/train.csv\"\n",
    "filename_test = \"../dataset/valid.csv\"\n",
    "\n",
    "train_rdd = spark.read.csv(filename_train, header=True, multiLine=True, inferSchema=True, escape='\"', quote='\"')\n",
    "test_rdd = spark.read.csv(filename_test, header=True, multiLine=True, inferSchema=True, escape='\"', quote='\"')\n",
    "train_rdd.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "lasting-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = train_rdd.rdd \\\n",
    "    .map(lambda x: (x[\"Title\"]+\" \"+x[\"Body\"], x[\"Y\"])) \\\n",
    "    .toDF([\"Question\", \"Output\"])# change to collect()\n",
    "\n",
    "testing = test_rdd.rdd \\\n",
    "    .map(lambda x: (x[\"Title\"]+\" \"+x[\"Body\"], x[\"Y\"])) \\\n",
    "    .toDF([\"Question\", \"Output\"]) # change to collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "golden-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "@metrics\n",
    "def load_train_test_rdd(filename_train, filename_test):\n",
    "    train_rdd = spark.read.csv(filename_train, header=True, multiLine=True, inferSchema=True, escape='\"', quote='\"')\n",
    "    test_rdd = spark.read.csv(filename_test, header=True, multiLine=True, inferSchema=True, escape='\"', quote='\"')\n",
    "    return train_rdd, test_rdd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "organizational-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "@metrics\n",
    "def transform_rdd_to_df(train_rdd,test_rdd):\n",
    "    training = train_rdd.rdd \\\n",
    "    .map(lambda x: (x[\"Title\"]+\" \"+x[\"Body\"], x[\"Y\"])) \\\n",
    "    .toDF([\"Question\", \"Output\"])\n",
    "\n",
    "    testing = test_rdd.rdd \\\n",
    "    .map(lambda x: (x[\"Title\"]+\" \"+x[\"Body\"], x[\"Y\"])) \\\n",
    "    .toDF([\"Question\", \"Output\"])\n",
    "    \n",
    "    return training, testing\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "statutory-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_train = \"../dataset/train.csv\"\n",
    "filename_test = \"../dataset/valid.csv\"\n",
    "train_rdd, test_rdd = load_train_test_rdd(filename_train, filename_test)\n",
    "train_df, test_df = transform_rdd_to_df(train_rdd,test_rdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-albania",
   "metadata": {},
   "source": [
    "# Prepare pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "weighted-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stop_word_remover(input_col_name, stopwords):\n",
    "    return StopWordsRemover(inputCol=input_col_name, outputCol=\"filtered\").setStopWords(stopwords)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hired-sweden",
   "metadata": {},
   "outputs": [],
   "source": [
    "@metrics\n",
    "def get_heuristics(stop_word_file):\n",
    "    # HEURISTIC 1 - Tokenize the words\n",
    "    regexTokenizer = RegexTokenizer(inputCol=\"Question\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "    \n",
    "    # HEURISTIC 2 - Remove the stopwords\n",
    "    stop_words = []\n",
    "    with open(stop_word_file, \"r\") as text_file:\n",
    "        stop_words = text_file.read().split('\\n')\n",
    "    \n",
    "    stopwordsRemover = get_stop_word_remover(\"words\", stop_words)\n",
    "    \n",
    "    return regexTokenizer, stopwordsRemover\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acting-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # HEURISTIC 1 - Tokenize the words\n",
    "# regexTokenizer = RegexTokenizer(inputCol=\"Question\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "\n",
    "# # HEURISTIC 2 - Remove the stopwords\n",
    "# # Reading stopwords file and storing each word in a list by specifying the return to line delimiter\n",
    "# stop_words = []\n",
    "# text_file = open(\"../dataset/stop_words.txt\", \"r\")\n",
    "# stop_words = text_file.read().split('\\n')\n",
    "# # add_stopwords = [\"the\", \"a\", \"be\", \"of\", \"and\", \"to\", \"why\"] \n",
    "# stopwordsRemover = get_stop_word_remover(\"words\", stop_words)\n",
    "stop_word_file = \"../dataset/stop_words.txt\"\n",
    "regexTokenizer, stopwordsRemover = get_heuristics(stop_word_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "liquid-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "@metrics\n",
    "def get_bag_of_word_model(features_col_name, label_col_name):\n",
    "    countVectors = CountVectorizer(inputCol=features_col_name, outputCol=\"features\")\n",
    "    indexed_features = StringIndexer(inputCol = label_col_name, outputCol = \"label\")\n",
    "    return countVectors, indexed_features\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "stretch-forty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEMINFO\n",
      "\n",
      "CPU in use: 7.7%\n",
      "Uptime: 19:21:47.528509\n",
      "Disk in use: 65.5%\n",
      "Memory in use: 6.625556945800781GiB\n",
      "Dsik free: 5.49658203125GiB\n",
      "Time on CPU: 7:36:48.240000\n",
      "\n",
      "\n",
      " AFTER CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEMINFO\n",
      "\n",
      "CPU in use: 0.0%\n",
      "Uptime: 19:21:47.660760\n",
      "Disk in use: 65.5%\n",
      "Memory in use: 6.624839782714844GiB\n",
      "Dsik free: 5.49658203125GiB\n",
      "Time on CPU: 7:36:48.240000\n",
      "Execution Time: 0.03131103515625\n",
      "BEFORE CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEMINFO\n",
      "\n",
      "CPU in use: 0.0%\n",
      "Uptime: 19:21:47.761858\n",
      "Disk in use: 65.5%\n",
      "Memory in use: 6.624351501464844GiB\n",
      "Dsik free: 5.49658203125GiB\n",
      "Time on CPU: 7:36:48.240000\n",
      "\n",
      "\n",
      " AFTER CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEMINFO\n",
      "\n",
      "CPU in use: 0.0%\n",
      "Uptime: 19:21:47.871834\n",
      "Disk in use: 65.5%\n",
      "Memory in use: 6.623928070068359GiB\n",
      "Dsik free: 5.49658203125GiB\n",
      "Time on CPU: 7:36:48.240000\n",
      "Execution Time: 0.009263992309570312\n"
     ]
    }
   ],
   "source": [
    "countVectors_h1, indexed_features_h1 = get_bag_of_word_model(\"words\", \"Output\")\n",
    "countVectors_h2, indexed_features_h2 = get_bag_of_word_model(\"filtered\", \"Output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "built-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "@metrics\n",
    "def get_pipeline(*args):\n",
    "    return Pipeline(stages=[*args])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "historical-quality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEMINFO\n",
      "\n",
      "CPU in use: 6.3%\n",
      "Uptime: 19:21:52.424083\n",
      "Disk in use: 65.5%\n",
      "Memory in use: 6.653079986572266GiB\n",
      "Dsik free: 5.496364593505859GiB\n",
      "Time on CPU: 7:36:51.890000\n",
      "\n",
      "\n",
      " AFTER CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEMINFO\n",
      "\n",
      "CPU in use: 4.9%\n",
      "Uptime: 19:21:52.527166\n",
      "Disk in use: 65.5%\n",
      "Memory in use: 6.653156280517578GiB\n",
      "Dsik free: 5.496364593505859GiB\n",
      "Time on CPU: 7:36:51.940000\n",
      "Execution Time: 0.0004260540008544922\n",
      "BEFORE CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEMINFO\n",
      "\n",
      "CPU in use: 4.8%\n",
      "Uptime: 19:21:52.628059\n",
      "Disk in use: 65.5%\n",
      "Memory in use: 6.653175354003906GiB\n",
      "Dsik free: 5.496364593505859GiB\n",
      "Time on CPU: 7:36:51.980000\n",
      "\n",
      "\n",
      " AFTER CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEMINFO\n",
      "\n",
      "CPU in use: 0.0%\n",
      "Uptime: 19:21:52.734210\n",
      "Disk in use: 65.5%\n",
      "Memory in use: 6.653194427490234GiB\n",
      "Dsik free: 5.496364593505859GiB\n",
      "Time on CPU: 7:36:51.980000\n",
      "Execution Time: 0.0003941059112548828\n"
     ]
    }
   ],
   "source": [
    "pipeline_h1 = get_pipeline(regexTokenizer, countVectors_h1, indexed_features_h1)\n",
    "pipeline_h2 = get_pipeline(regexTokenizer, stopwordsRemover, countVectors_h2, indexed_features_h2)\n",
    "# pipeline_h3 = get_pipeline(regexTokenizer, stopwordsRemover, countVectors_h2, indexed_features_h2,stemmer_udf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-castle",
   "metadata": {},
   "source": [
    "# Process data through Pipeline train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "respected-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "@metrics\n",
    "def get_pipeline_model(pipeline, data):\n",
    "    \"\"\" We should use the same pipeline model on training and testing \"\"\"\n",
    "    return pipeline.fit(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sixth-divide",
   "metadata": {},
   "outputs": [],
   "source": [
    "@metrics\n",
    "def transform_data_through_pipeline(model, data):\n",
    "    data_transformed = model.transform(data)\n",
    "    return data_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "mathematical-brush",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 16.91487216949463\n",
      "+--------------------+--------+--------------------+--------------------+-----+\n",
      "|            Question|  Output|               words|            features|label|\n",
      "+--------------------+--------+--------------------+--------------------+-----+\n",
      "|Java: Repeat Task...|LQ_CLOSE|[java, repeat, ta...|(201488,[0,1,2,3,...|  1.0|\n",
      "|Why are Java Opti...|      HQ|[why, are, java, ...|(201488,[0,1,4,7,...|  0.0|\n",
      "|Text Overlay Imag...|      HQ|[text, overlay, i...|(201488,[0,1,2,3,...|  0.0|\n",
      "|Why ternary opera...|      HQ|[why, ternary, op...|(201488,[0,1,2,3,...|  0.0|\n",
      "|hide/show fab wit...|      HQ|[hide, show, fab,...|(201488,[0,1,4,5,...|  0.0|\n",
      "|Accessing pointer...|LQ_CLOSE|[accessing, point...|(201488,[0,1,2,3,...|  1.0|\n",
      "|How To Disable 2n...| LQ_EDIT|[how, to, disable...|(201488,[1,4,8,15...|  2.0|\n",
      "|Resizing containe...| LQ_EDIT|[resizing, contai...|(201488,[1,2,3,4,...|  2.0|\n",
      "|Changing Theme in...|      HQ|[changing, theme,...|(201488,[0,1,2,3,...|  0.0|\n",
      "|TextBox Value Dis...| LQ_EDIT|[textbox, value, ...|(201488,[1,6,7,8,...|  2.0|\n",
      "|MongoDB Failing t...|      HQ|[mongodb, failing...|(201488,[0,1,3,4,...|  0.0|\n",
      "|What's the best w...|LQ_CLOSE|[what, s, the, be...|(201488,[0,1,2,3,...|  1.0|\n",
      "|ios/objective-c/x...| LQ_EDIT|[ios, objective, ...|(201488,[1,2,4,5,...|  2.0|\n",
      "|output FILE ,is t...| LQ_EDIT|[output, file, is...|(201488,[1,2,3,4,...|  2.0|\n",
      "|Pod install displ...|      HQ|[pod, install, di...|(201488,[0,2,3,4,...|  0.0|\n",
      "|Haskell Stack Ghc...|      HQ|[haskell, stack, ...|(201488,[0,1,2,3,...|  0.0|\n",
      "|Why does the reve...|      HQ|[why, does, the, ...|(201488,[0,1,2,3,...|  0.0|\n",
      "|eb deploy does no...|      HQ|[eb, deploy, does...|(201488,[0,1,2,3,...|  0.0|\n",
      "|How to create a f...| LQ_EDIT|[how, to, create,...|(201488,[1,2,3,4,...|  2.0|\n",
      "|bluebird.js vs bl...|      HQ|[bluebird, js, vs...|(201488,[0,1,2,4,...|  0.0|\n",
      "+--------------------+--------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model_pipeline = pipeline_h1.fit(training)\n",
    "model_pipeline = get_pipeline_model(pipeline_h1, training)\n",
    "data_h1_train = transform_data_through_pipeline(model_pipeline, train_df)\n",
    "data_h1_test = transform_data_through_pipeline(model_pipeline, test_df)\n",
    "# data_h1_train  = model_pipeline.transform(training) #what does the transform do?\n",
    "data_h1_train = train_mail\n",
    "data_h1_train.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-contamination",
   "metadata": {},
   "source": [
    "**Vocabulary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "white-triangle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1293400': 1, 'mypass': 5, 'connected': 433, 'few': 902, 'input': 9663, 'online': 599, '389999': 1, 'travel': 74, '836400': 1, 'those': 1212, 'still': 2194, 'thread1': 26, 'hope': 513, 'recognize': 120, 'parentheses': 89, 'arguments': 696, 'persist': 74, '2bxhsys2c47eyjfhpmroalpxz5suigeubqu7hjuvfvwpoa0xri3iljvhq5qgbwtwpe1x0': 2, 'pabu': 1, 'some': 8532}\n"
     ]
    }
   ],
   "source": [
    "# vocabulary frequency without using the countVectorizer helper column that we generated\n",
    "counts = data_h1_train.select(f.explode('words').alias('col')).groupBy('col').count().take(20)\n",
    "print({row['col']: row['count'] for row in counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "tutorial-aircraft",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-7b4ae0958939>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# using the countVectorizer helper column that we generated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_h1_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'words'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vectors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# using the countVectorizer helper column that we generated\n",
    "# https://stackoverflow.com/questions/50255356/pyspark-countvectorizer-and-word-frequency-in-a-corpus\n",
    "counts = data_h1_train.select('words').take(20)\n",
    "print(dict(zip(vocabulary, counts[0]['words'].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "perceived-county",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------------------+-----+\n",
      "|            Question|  Output|               words|            features|label|\n",
      "+--------------------+--------+--------------------+--------------------+-----+\n",
      "|How to get all th...| LQ_EDIT|[how, to, get, al...|(86590,[1,2,4,6,9...|  2.0|\n",
      "|Retrieve all exce...| LQ_EDIT|[retrieve, all, e...|(86590,[1,2,7,9,1...|  2.0|\n",
      "|Pandas: read_html...|      HQ|[pandas, read_htm...|(86590,[0,1,2,3,4...|  0.0|\n",
      "|Reader Always gim...| LQ_EDIT|[reader, always, ...|(86590,[1,2,4,5,7...|  2.0|\n",
      "|php rearrange arr...| LQ_EDIT|[php, rearrange, ...|(86590,[1,2,4,5,6...|  2.0|\n",
      "|How do I make a c...|LQ_CLOSE|[how, do, i, make...|(86590,[0,1,2,3,4...|  1.0|\n",
      "|how can i create ...| LQ_EDIT|[how, can, i, cre...|(86590,[1,5,6,9,1...|  2.0|\n",
      "|Re-exporting ES6 ...|      HQ|[re, exporting, e...|(86590,[0,1,2,3,4...|  0.0|\n",
      "|Fetch API with Co...|      HQ|[fetch, api, with...|(86590,[0,1,2,4,5...|  0.0|\n",
      "|Print list conten...|LQ_CLOSE|[print, list, con...|(86590,[0,1,2,3,4...|  1.0|\n",
      "|c# - List all pri...| LQ_EDIT|[c, list, all, pr...|(86590,[1,2,3,4,5...|  2.0|\n",
      "|Angular2 exceptio...|      HQ|[angular2, except...|(86590,[0,3,11,21...|  0.0|\n",
      "|Form Validation p...|LQ_CLOSE|[form, validation...|(86590,[0,1,2,4,5...|  1.0|\n",
      "|Most Pythonic way...|      HQ|[most, pythonic, ...|(86590,[0,1,2,3,4...|  0.0|\n",
      "|Gulp error intern...|      HQ|[gulp, error, int...|(86590,[0,1,2,4,9...|  0.0|\n",
      "|Filter Name with ...| LQ_EDIT|[filter, name, wi...|(86590,[1,2,3,4,6...|  2.0|\n",
      "|Django ImageField...|      HQ|[django, imagefie...|(86590,[0,1,2,3,4...|  0.0|\n",
      "|Compiling SASS in...|LQ_CLOSE|[compiling, sass,...|(86590,[0,1,4,5,6...|  1.0|\n",
      "|to get or set the...| LQ_EDIT|[to, get, or, set...|(86590,[1,2,3,4,5...|  2.0|\n",
      "|i am new to pythn...| LQ_EDIT|[i, am, new, to, ...|(86590,[1,3,4,7,9...|  2.0|\n",
      "+--------------------+--------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_h1_test = process_data_in_pipeline(pipeline_h1, testing)\n",
    "data_h1_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "focal-least",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------------------+-----+\n",
      "|            Question|  Output|               words|            features|label|\n",
      "+--------------------+--------+--------------------+--------------------+-----+\n",
      "|How to get all th...| LQ_EDIT|[how, to, get, al...|(201488,[1,2,4,6,...|  2.0|\n",
      "|Retrieve all exce...| LQ_EDIT|[retrieve, all, e...|(201488,[1,2,7,8,...|  2.0|\n",
      "|Pandas: read_html...|      HQ|[pandas, read_htm...|(201488,[0,1,2,3,...|  0.0|\n",
      "|Reader Always gim...| LQ_EDIT|[reader, always, ...|(201488,[1,2,4,5,...|  2.0|\n",
      "|php rearrange arr...| LQ_EDIT|[php, rearrange, ...|(201488,[1,2,4,5,...|  2.0|\n",
      "|How do I make a c...|LQ_CLOSE|[how, do, i, make...|(201488,[0,1,2,3,...|  1.0|\n",
      "|how can i create ...| LQ_EDIT|[how, can, i, cre...|(201488,[1,5,6,8,...|  2.0|\n",
      "|Re-exporting ES6 ...|      HQ|[re, exporting, e...|(201488,[0,1,2,3,...|  0.0|\n",
      "|Fetch API with Co...|      HQ|[fetch, api, with...|(201488,[0,1,2,4,...|  0.0|\n",
      "|Print list conten...|LQ_CLOSE|[print, list, con...|(201488,[0,1,2,3,...|  1.0|\n",
      "|c# - List all pri...| LQ_EDIT|[c, list, all, pr...|(201488,[1,2,3,4,...|  2.0|\n",
      "|Angular2 exceptio...|      HQ|[angular2, except...|(201488,[0,3,11,2...|  0.0|\n",
      "|Form Validation p...|LQ_CLOSE|[form, validation...|(201488,[0,1,2,4,...|  1.0|\n",
      "|Most Pythonic way...|      HQ|[most, pythonic, ...|(201488,[0,1,2,3,...|  0.0|\n",
      "|Gulp error intern...|      HQ|[gulp, error, int...|(201488,[0,1,2,4,...|  0.0|\n",
      "|Filter Name with ...| LQ_EDIT|[filter, name, wi...|(201488,[1,2,3,4,...|  2.0|\n",
      "|Django ImageField...|      HQ|[django, imagefie...|(201488,[0,1,2,3,...|  0.0|\n",
      "|Compiling SASS in...|LQ_CLOSE|[compiling, sass,...|(201488,[0,1,4,5,...|  1.0|\n",
      "|to get or set the...| LQ_EDIT|[to, get, or, set...|(201488,[1,2,3,4,...|  2.0|\n",
      "|i am new to pythn...| LQ_EDIT|[i, am, new, to, ...|(201488,[1,3,4,7,...|  2.0|\n",
      "+--------------------+--------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_h1_test  = model_pipeline.transform(testing)\n",
    "data_h1_test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-saudi",
   "metadata": {},
   "source": [
    "# Split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "about-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "@metrics\n",
    "def split_dataset(data, distribution):\n",
    "    return data.randomSplit([distribution, 1-distribution], seed = 1234)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "tracked-barrel",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_h1, validate_h1 = split_dataset(data_h1_train, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "demanding-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1,test2 = split_dataset(data_h1_test, 0.7) # just for testing purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-twenty",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning | is this doing anything? we are not using any data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sonic-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "@metrics\n",
    "def get_best_smoothing_values(target_col, prediction_col):\n",
    "    # Create grid to find best smoothing\n",
    "    nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "    paramGrid = ParamGridBuilder().addGrid(nb.smoothing, [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]).build()\n",
    "#     cvEvaluator = BinaryClassificationEvaluator(rawPredictionCol=prediction_col)\n",
    "    cvEvaluator = MulticlassClassificationEvaluator(labelCol=target_col, predictionCol=prediction_col)\n",
    "\n",
    "    # Cross-validate all smoothing values\n",
    "    cv = CrossValidator(estimator=nb, estimatorParamMaps=paramGrid, evaluator=cvEvaluator)\n",
    "    return cv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "stylish-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = get_best_smoothing_values(\"label\", \"prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-architect",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "crazy-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "@metrics\n",
    "def train_naive_bayes_model(cv, data):\n",
    "    model = cv.fit(data)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sunrise-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvModel = cv.fit(train_h1)\n",
    "nb_model = train_naive_bayes_model(cv,train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-rehabilitation",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "technical-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "@metrics\n",
    "def predict(model, data):\n",
    "    predictions = model.transform(data)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "flexible-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation set\n",
    "# cvPredictions = cvModel.transform(validate_h1)\n",
    "predictions = predict(nb_model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "challenging-ontario",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cvPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "noble-technology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  2.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  2.0|       2.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       0.0|\n",
      "|  1.0|       1.0|\n",
      "|  0.0|       1.0|\n",
      "|  2.0|       2.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       1.0|\n",
      "+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cvPredictions.select(\"label\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "outdoor-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvPredictions_test = cvModel.transform(data_h1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "attempted-indonesia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  2.0|       2.0|\n",
      "|  2.0|       2.0|\n",
      "|  0.0|       0.0|\n",
      "|  2.0|       2.0|\n",
      "|  2.0|       2.0|\n",
      "|  1.0|       1.0|\n",
      "|  2.0|       2.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       0.0|\n",
      "|  2.0|       1.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       0.0|\n",
      "|  0.0|       1.0|\n",
      "|  0.0|       0.0|\n",
      "|  2.0|       2.0|\n",
      "|  0.0|       0.0|\n",
      "|  1.0|       0.0|\n",
      "|  2.0|       2.0|\n",
      "|  2.0|       2.0|\n",
      "+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cvPredictions_test.select(\"label\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-cooking",
   "metadata": {},
   "source": [
    "# Evaluate Performance of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sized-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "@metrics\n",
    "def evaluate_model(target_col, prediction_col, predictionAndTarget):\n",
    "#     evaluator = BinaryClassificationEvaluator(rawPredictionCol=prediction_col)\n",
    "    evaluatorMulti = MulticlassClassificationEvaluator(labelCol=target_col, predictionCol=prediction_col)\n",
    "#     accuracy = evaluatorMulti.evaluate(predictions)\n",
    "    # Get metrics\n",
    "    acc = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"accuracy\"})\n",
    "    f1 = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"f1\"})\n",
    "    weightedPrecision = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"weightedPrecision\"})\n",
    "    weightedRecall = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"weightedRecall\"})\n",
    "#     auc = evaluator.evaluate(predictionAndTarget)\n",
    "    print(\"\\n******** Metrics **********\")\n",
    "    print (\"Model Accuracy: {:.3f}%\".format(acc*100))\n",
    "    print (\"Model f1-score: {:.3f}%\".format(f1*100))\n",
    "    print (\"Model weightedPrecision: {:.3f}%\".format(weightedPrecision*100))\n",
    "    print (\"Model weightedRecall: {:.3f}%\".format(weightedRecall*100))\n",
    "#     return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "essential-services",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.7653008490217793\n",
      "Model f1-score:  0.7675841714238029\n",
      "Model weightedPrecision:  0.7901628512971111\n",
      "Model weightedRecall:  0.7653008490217792\n"
     ]
    }
   ],
   "source": [
    "# Validation Dataset\n",
    "evaluate_model(\"label\", \"prediction\", cvPredictions.select(\"label\",\"prediction\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "instructional-extreme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.7633333333333333\n",
      "Model f1-score:  0.7649182102284617\n",
      "Model weightedPrecision:  0.7866094786891012\n",
      "Model weightedRecall:  0.7633333333333333\n"
     ]
    }
   ],
   "source": [
    "# testing dataset\n",
    "evaluate_model(\"label\", \"prediction\", cvPredictions_test.select(\"label\",\"prediction\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-university",
   "metadata": {},
   "source": [
    "# Creating one big iteration for all the pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "latter-start",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######Pipeline 1#######\n",
      "**Creating pipeline model**\n",
      "Time: 16.767117977142334\n",
      "**Transforming training data**\n",
      "**Transforming testing data**\n",
      "**Hyperparameter tuning**\n",
      "Time: 0.03666400909423828\n",
      "**Training the model**\n",
      "**predicting on testing dataset**\n",
      "**Measuring performance**\n",
      "Model Accuracy:  0.7734666666666666\n",
      "Model f1-score:  0.7755420672257562\n",
      "Model weightedPrecision:  0.7947480066182155\n",
      "Model weightedRecall:  0.7734666666666666\n",
      "Time: 28.150495052337646\n",
      "#######Pipeline 2#######\n",
      "**Creating pipeline model**\n",
      "Time: 17.788862943649292\n",
      "**Transforming training data**\n",
      "**Transforming testing data**\n",
      "**Hyperparameter tuning**\n",
      "Time: 0.011992931365966797\n",
      "**Training the model**\n",
      "**predicting on testing dataset**\n",
      "**Measuring performance**\n",
      "Model Accuracy:  0.7816\n",
      "Model f1-score:  0.7840113017879425\n",
      "Model weightedPrecision:  0.7998494840023584\n",
      "Model weightedRecall:  0.7816\n",
      "Time: 33.55508613586426\n",
      "CPU times: user 1.29 s, sys: 238 ms, total: 1.53 s\n",
      "Wall time: 4min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for pipeline, pipe_name in zip([pipeline_h1, pipeline_h2],[\"Pipeline 1\",\"Pipeline 2\"]):\n",
    "    print(\"#######\"+ pipe_name + \"#######\")\n",
    "    print(\"**\"+ \"Creating pipeline model\" + \"**\") \n",
    "    model_pipeline = get_pipeline_model(pipeline, training)\n",
    "    print(\"**\"+ \"Transforming training data\" + \"**\") \n",
    "    data_train  = model_pipeline.transform(training)\n",
    "    print(\"**\"+ \"Transforming testing data\" + \"**\") \n",
    "    data_test  = model_pipeline.transform(testing)\n",
    "    print(\"**\"+ \"Hyperparameter tuning\" + \"**\") \n",
    "    cv = get_best_smoothing_values(\"label\", \"prediction\")\n",
    "    print(\"**\"+ \"Training the model\" + \"**\") \n",
    "    cvModel = cv.fit(data_train)\n",
    "    print(\"**\"+ \"predicting on testing dataset\" + \"**\") \n",
    "    cvPredictions = cvModel.transform(data_test)\n",
    "    print(\"**\"+ \"Measuring performance\" + \"**\")\n",
    "    evaluate_model(\"label\", \"prediction\", cvPredictions.select(\"label\",\"prediction\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ideal-amateur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######Pipeline 1#######\n",
      "**Creating pipeline model**\n",
      "BEFORE CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEMINFO\n",
      "\n",
      "CPU in use: 6.3%\n",
      "Uptime: 19:22:16.616642\n",
      "Disk in use: 65.5%\n",
      "Memory in use: 6.592823028564453GiB\n",
      "Dsik free: 5.492912292480469GiB\n",
      "Time on CPU: 7:37:10.150000\n",
      "\n",
      "\n",
      " AFTER CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEMINFO\n",
      "\n",
      "CPU in use: 7.3%\n",
      "Uptime: 19:22:35.311528\n",
      "Disk in use: 65.5%\n",
      "Memory in use: 6.654502868652344GiB\n",
      "Dsik free: 5.490562438964844GiB\n",
      "Time on CPU: 7:37:53.890000\n",
      "Execution Time: 18.59303617477417\n",
      "**Transforming training data**\n",
      "**Transforming testing data**\n",
      "**Hyperparameter tuning**\n",
      "BEFORE CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEMINFO\n",
      "\n",
      "CPU in use: 4.9%\n",
      "Uptime: 19:22:35.705788\n",
      "Disk in use: 65.5%\n",
      "Memory in use: 6.679847717285156GiB\n",
      "Dsik free: 5.490562438964844GiB\n",
      "Time on CPU: 7:37:54.660000\n",
      "\n",
      "\n",
      " AFTER CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEMINFO\n",
      "\n",
      "CPU in use: 0.0%\n",
      "Uptime: 19:22:35.849007\n",
      "Disk in use: 65.5%\n",
      "Memory in use: 6.686481475830078GiB\n",
      "Dsik free: 5.490562438964844GiB\n",
      "Time on CPU: 7:37:54.660000\n",
      "Execution Time: 0.0417780876159668\n",
      "**Training the model**\n",
      "**predicting on testing dataset**\n",
      "**Measuring performance**\n",
      "BEFORE CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEMINFO\n",
      "\n",
      "CPU in use: 2.5%\n",
      "Uptime: 19:24:03.851043\n",
      "Disk in use: 65.5%\n",
      "Memory in use: 6.5320587158203125GiB\n",
      "Dsik free: 5.49517822265625GiB\n",
      "Time on CPU: 7:41:32.970000\n",
      "Model Accuracy:  0.7726\n",
      "Model f1-score:  0.7746909975733439\n",
      "Model weightedPrecision:  0.7939332260574594\n",
      "Model weightedRecall:  0.7726\n",
      "\n",
      "\n",
      " AFTER CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEMINFO\n",
      "\n",
      "CPU in use: 10.6%\n",
      "Uptime: 19:24:29.957896\n",
      "Disk in use: 65.5%\n",
      "Memory in use: 6.675502777099609GiB\n",
      "Dsik free: 5.496807098388672GiB\n",
      "Time on CPU: 7:42:31.300000\n",
      "Execution Time: 26.001079082489014\n",
      "#######Pipeline 2 with new stop words#######\n",
      "**Creating pipeline model**\n",
      "BEFORE CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEMINFO\n",
      "\n",
      "CPU in use: 7.2%\n",
      "Uptime: 19:24:30.062591\n",
      "Disk in use: 65.5%\n",
      "Memory in use: 6.675529479980469GiB\n",
      "Dsik free: 5.496807098388672GiB\n",
      "Time on CPU: 7:42:31.360000\n",
      "\n",
      "\n",
      " AFTER CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEMINFO\n",
      "\n",
      "CPU in use: 6.3%\n",
      "Uptime: 19:24:46.666341\n",
      "Disk in use: 65.5%\n",
      "Memory in use: 6.721271514892578GiB\n",
      "Dsik free: 5.496635437011719GiB\n",
      "Time on CPU: 7:43:04.180000\n",
      "Execution Time: 16.500602960586548\n",
      "**Transforming training data**\n",
      "**Transforming testing data**\n",
      "**Hyperparameter tuning**\n",
      "BEFORE CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEMINFO\n",
      "\n",
      "CPU in use: 6.3%\n",
      "Uptime: 19:24:47.095612\n",
      "Disk in use: 65.5%\n",
      "Memory in use: 6.7135009765625GiB\n",
      "Dsik free: 5.496635437011719GiB\n",
      "Time on CPU: 7:43:05.100000\n",
      "\n",
      "\n",
      " AFTER CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEMINFO\n",
      "\n",
      "CPU in use: 0.0%\n",
      "Uptime: 19:24:47.204354\n",
      "Disk in use: 65.5%\n",
      "Memory in use: 6.713527679443359GiB\n",
      "Dsik free: 5.496635437011719GiB\n",
      "Time on CPU: 7:43:05.100000\n",
      "Execution Time: 0.007964134216308594\n",
      "**Training the model**\n",
      "**predicting on testing dataset**\n",
      "**Measuring performance**\n",
      "BEFORE CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEMINFO\n",
      "\n",
      "CPU in use: 4.9%\n",
      "Uptime: 19:26:15.605581\n",
      "Disk in use: 65.5%\n",
      "Memory in use: 6.686923980712891GiB\n",
      "Dsik free: 5.483486175537109GiB\n",
      "Time on CPU: 7:46:03.790000\n",
      "Model Accuracy:  0.7816\n",
      "Model f1-score:  0.7840113017879425\n",
      "Model weightedPrecision:  0.7998494840023584\n",
      "Model weightedRecall:  0.7816\n",
      "\n",
      "\n",
      " AFTER CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEMINFO\n",
      "\n",
      "CPU in use: 3.7%\n",
      "Uptime: 19:26:42.111897\n",
      "Disk in use: 65.5%\n",
      "Memory in use: 6.540996551513672GiB\n",
      "Dsik free: 5.484184265136719GiB\n",
      "Time on CPU: 7:47:05.590000\n",
      "Execution Time: 26.405650854110718\n",
      "CPU times: user 1.27 s, sys: 238 ms, total: 1.51 s\n",
      "Wall time: 4min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for pipeline, pipe_name in zip([pipeline_h1, pipeline_h2],[\"Pipeline 1\",\"Pipeline 2 with new stop words\"]):\n",
    "    print(\"#######\"+ pipe_name + \"#######\")\n",
    "    print(\"**\"+ \"Creating pipeline model\" + \"**\") \n",
    "    model_pipeline = get_pipeline_model(pipeline, training)\n",
    "    print(\"**\"+ \"Transforming training data\" + \"**\") \n",
    "    data_train  = model_pipeline.transform(training)\n",
    "    print(\"**\"+ \"Transforming testing data\" + \"**\") \n",
    "    data_test  = model_pipeline.transform(testing)\n",
    "    print(\"**\"+ \"Hyperparameter tuning\" + \"**\") \n",
    "    cv = get_best_smoothing_values(\"label\", \"prediction\")\n",
    "    print(\"**\"+ \"Training the model\" + \"**\") \n",
    "    cvModel = cv.fit(data_train)\n",
    "    print(\"**\"+ \"predicting on testing dataset\" + \"**\") \n",
    "    cvPredictions = cvModel.transform(data_test)\n",
    "    print(\"**\"+ \"Measuring performance\" + \"**\")\n",
    "    evaluate_model(\"label\", \"prediction\", cvPredictions.select(\"label\",\"prediction\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sufficient-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_spark():\n",
    "    print(\"##########################################\")\n",
    "    print(\"############# Start Spark ################\")\n",
    "    print(\"##########################################\")\n",
    "    global spark\n",
    "    spark = init_spark()\n",
    "    filename_train = \"../dataset/train.csv\"\n",
    "    filename_test = \"../dataset/valid.csv\"\n",
    "    stop_word_file = \"../dataset/stop_words.txt\"\n",
    "    print(\"\\n#########################################\")\n",
    "    print(\"####### Load dataset in spark rdd #######\")\n",
    "    print(\"###########################################\")\n",
    "    train_rdd, test_rdd = load_train_test_rdd(filename_train, filename_test)\n",
    "    print(\"\\n#########################################\")\n",
    "    print(\"########## Transform rdd to df ############\")\n",
    "    print(\"##########################################\")\n",
    "    train_df, test_df = transform_rdd_to_df(train_rdd,test_rdd)\n",
    "    print(\"\\n##########################################\")\n",
    "    print(\"########## Create Heuristics #############\")\n",
    "    print(\"##########################################\")\n",
    "    regexTokenizer, stopwordsRemover = get_heuristics(stop_word_file)\n",
    "    countVectors_h1, indexed_features_h1 = get_bag_of_word_model(\"words\", \"Output\")\n",
    "    countVectors_h2, indexed_features_h2 = get_bag_of_word_model(\"filtered\", \"Output\")\n",
    "    print(\"\\n##########################################\")\n",
    "    print(\"############ Construct pipeline ############\")\n",
    "    print(\"############################################\")\n",
    "    pipeline = get_pipeline(regexTokenizer, stopwordsRemover, countVectors_h2, indexed_features_h2)\n",
    "    print(\"\\n##########################################\")\n",
    "    print(\"########### Train pipeline model ###########\")\n",
    "    print(\"############################################\")\n",
    "    model_pipeline = get_pipeline_model(pipeline, train_df)\n",
    "    print(\"\\n#############################################\")\n",
    "    print(\"####### Transform train data through pipeline #####\")\n",
    "    print(\"################################################\")\n",
    "    train = transform_data_through_pipeline(model_pipeline, train_df)\n",
    "    print(\"\\n##################################################\")\n",
    "    print(\"####### Transform test data through pipeline #######\")\n",
    "    print(\"##################################################\")\n",
    "    test = transform_data_through_pipeline(model_pipeline, test_df)\n",
    "    print(\"\\n###################################################\")\n",
    "    print(\"####### Train naive base classifier model #######\")\n",
    "    print(\"####################################################\")\n",
    "    cv = get_best_smoothing_values(\"label\", \"prediction\")\n",
    "    nb_model = train_naive_bayes_model(cv,train)\n",
    "    print(\"\\n##############################################################\")\n",
    "    print(\"### Predict test data using naive base classifier model ######\")\n",
    "    print(\"################################################################\")\n",
    "    predictions = predict(nb_model, test)\n",
    "    print(\"####################################\")\n",
    "    print(\"####### Evaluate predictions #######\")\n",
    "    print(\"#####################################\")\n",
    "    evaluate_model(\"label\", \"prediction\",predictions.select(\"label\",\"prediction\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fifteen-motion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### Start Spark #######\n",
      "####### Load dataset in spark rdd #######\n",
      "####### Transform rdd to df #######\n",
      "####### Create Heuristics #######\n",
      "####### Construct pipeline #######\n",
      "####### Train pipeline model #######\n",
      "####### Transform train data through pipeline #######\n",
      "####### Transform test data through pipeline #######\n",
      "####### Train naive base classifier model #######\n",
      "####### Predict test data using naive base classifier model #######\n",
      "####### Evaluate predictions #######\n",
      "Model Accuracy: 78.227%\n",
      "Model f1-score: 78.464%\n",
      "Model weightedPrecision: 80.089%\n",
      "Model weightedRecall: 78.227%\n",
      "CPU times: user 864 ms, sys: 159 ms, total: 1.02 s\n",
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "main_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "blind-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "%%time\n",
    "main_spark()\n",
    "with open('output2.txt', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "logical-double",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################\n",
      "############# Start Spark ################\n",
      "##########################################\n",
      "BEFORE CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Time on CPU: 2:57:02.850000\n",
      "CPU in use: 21.80%\n",
      "Disk in use: 59.50%\n",
      "Memory in use: 8.21GiB\n",
      "Disk free: 7.11GiB\n",
      "\n",
      "\n",
      " AFTER CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Time on CPU: 2:57:02.930000\n",
      "CPU in use: 9.40%\n",
      "Disk in use: 59.50%\n",
      "Memory in use: 8.21GiB\n",
      "Disk free: 7.11GiB\n",
      "Execution Time: 0.0032379627227783203\n",
      "\n",
      "#########################################\n",
      "####### Load dataset in spark rdd #######\n",
      "###########################################\n",
      "BEFORE CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Time on CPU: 2:57:02.930000\n",
      "CPU in use: 0.00%\n",
      "Disk in use: 59.50%\n",
      "Memory in use: 8.21GiB\n",
      "Disk free: 7.11GiB\n",
      "\n",
      "\n",
      " AFTER CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Time on CPU: 2:57:05.980000\n",
      "CPU in use: 15.90%\n",
      "Disk in use: 59.50%\n",
      "Memory in use: 8.20GiB\n",
      "Disk free: 7.11GiB\n",
      "Execution Time: 1.190539836883545\n",
      "\n",
      "#########################################\n",
      "########## Transform rdd to df ############\n",
      "##########################################\n",
      "BEFORE CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Time on CPU: 2:57:05.980000\n",
      "CPU in use: 0.00%\n",
      "Disk in use: 59.50%\n",
      "Memory in use: 8.20GiB\n",
      "Disk free: 7.11GiB\n",
      "\n",
      "\n",
      " AFTER CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Time on CPU: 2:57:05.980000\n",
      "CPU in use: 0.00%\n",
      "Disk in use: 59.50%\n",
      "Memory in use: 8.20GiB\n",
      "Disk free: 7.11GiB\n",
      "Execution Time: 0.17874717712402344\n",
      "\n",
      "##########################################\n",
      "########## Create Heuristics #############\n",
      "##########################################\n",
      "BEFORE CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Time on CPU: 2:57:05.980000\n",
      "CPU in use: 0.00%\n",
      "Disk in use: 59.50%\n",
      "Memory in use: 8.20GiB\n",
      "Disk free: 7.11GiB\n",
      "\n",
      "\n",
      " AFTER CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Time on CPU: 2:57:05.980000\n",
      "CPU in use: 0.00%\n",
      "Disk in use: 59.50%\n",
      "Memory in use: 8.20GiB\n",
      "Disk free: 7.11GiB\n",
      "Execution Time: 0.05257582664489746\n",
      "BEFORE CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Time on CPU: 2:57:05.980000\n",
      "CPU in use: 0.00%\n",
      "Disk in use: 59.50%\n",
      "Memory in use: 8.20GiB\n",
      "Disk free: 7.11GiB\n",
      "\n",
      "\n",
      " AFTER CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Time on CPU: 2:57:05.980000\n",
      "CPU in use: 0.00%\n",
      "Disk in use: 59.50%\n",
      "Memory in use: 8.20GiB\n",
      "Disk free: 7.11GiB\n",
      "Execution Time: 0.007414102554321289\n",
      "BEFORE CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Time on CPU: 2:57:07.210000\n",
      "CPU in use: 16.30%\n",
      "Disk in use: 59.50%\n",
      "Memory in use: 8.20GiB\n",
      "Disk free: 7.11GiB\n",
      "\n",
      "\n",
      " AFTER CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Time on CPU: 2:57:07.290000\n",
      "CPU in use: 7.10%\n",
      "Disk in use: 59.50%\n",
      "Memory in use: 8.21GiB\n",
      "Disk free: 7.11GiB\n",
      "Execution Time: 0.008183002471923828\n",
      "\n",
      "##########################################\n",
      "############ Construct pipeline ############\n",
      "############################################\n",
      "BEFORE CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Time on CPU: 2:57:07.290000\n",
      "CPU in use: 0.00%\n",
      "Disk in use: 59.50%\n",
      "Memory in use: 8.21GiB\n",
      "Disk free: 7.11GiB\n",
      "\n",
      "\n",
      " AFTER CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Time on CPU: 2:57:07.290000\n",
      "CPU in use: 0.00%\n",
      "Disk in use: 59.50%\n",
      "Memory in use: 8.21GiB\n",
      "Disk free: 7.11GiB\n",
      "Execution Time: 0.0006399154663085938\n",
      "\n",
      "##########################################\n",
      "########### Train pipeline model ###########\n",
      "############################################\n",
      "BEFORE CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Time on CPU: 2:57:07.290000\n",
      "CPU in use: 0.00%\n",
      "Disk in use: 59.50%\n",
      "Memory in use: 8.20GiB\n",
      "Disk free: 7.11GiB\n",
      "\n",
      "\n",
      " AFTER CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Time on CPU: 2:57:47.350000\n",
      "CPU in use: 11.40%\n",
      "Disk in use: 59.50%\n",
      "Memory in use: 8.20GiB\n",
      "Disk free: 7.11GiB\n",
      "Execution Time: 17.354730129241943\n",
      "\n",
      "#############################################\n",
      "####### Transform train data through pipeline #####\n",
      "################################################\n",
      "BEFORE CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Time on CPU: 2:57:47.450000\n",
      "CPU in use: 12.20%\n",
      "Disk in use: 59.50%\n",
      "Memory in use: 8.20GiB\n",
      "Disk free: 7.11GiB\n",
      "\n",
      "\n",
      " AFTER CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Time on CPU: 2:57:47.450000\n",
      "CPU in use: 0.00%\n",
      "Disk in use: 59.50%\n",
      "Memory in use: 8.20GiB\n",
      "Disk free: 7.11GiB\n",
      "Execution Time: 0.16550993919372559\n",
      "\n",
      "##################################################\n",
      "####### Transform test data through pipeline #######\n",
      "##################################################\n",
      "BEFORE CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Time on CPU: 2:57:47.450000\n",
      "CPU in use: 0.00%\n",
      "Disk in use: 59.50%\n",
      "Memory in use: 8.20GiB\n",
      "Disk free: 7.11GiB\n",
      "\n",
      "\n",
      " AFTER CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Time on CPU: 2:57:47.450000\n",
      "CPU in use: 0.00%\n",
      "Disk in use: 59.50%\n",
      "Memory in use: 8.20GiB\n",
      "Disk free: 7.11GiB\n",
      "Execution Time: 0.12750697135925293\n",
      "\n",
      "###################################################\n",
      "####### Train naive base classifier model #######\n",
      "####################################################\n",
      "BEFORE CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Time on CPU: 2:57:47.450000\n",
      "CPU in use: 0.00%\n",
      "Disk in use: 59.50%\n",
      "Memory in use: 8.20GiB\n",
      "Disk free: 7.11GiB\n",
      "\n",
      "\n",
      " AFTER CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Time on CPU: 2:57:48.700000\n",
      "CPU in use: 19.00%\n",
      "Disk in use: 59.50%\n",
      "Memory in use: 8.20GiB\n",
      "Disk free: 7.11GiB\n",
      "Execution Time: 0.014935970306396484\n",
      "BEFORE CALL TO FUNCTION\n",
      "\n",
      "\n",
      " SYSTEM INFO\n",
      "\n",
      "Time on CPU: 2:57:48.700000\n",
      "CPU in use: 0.00%\n",
      "Disk in use: 59.50%\n",
      "Memory in use: 8.20GiB\n",
      "Disk free: 7.11GiB\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/Users/robertbeaudenon/opt/anaconda3/envs/bigdata-lab/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3003de0b496a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain_spark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-0b8ab8bbdba8>\u001b[0m in \u001b[0;36mmain_spark\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"####################################################\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_best_smoothing_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mnb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_naive_bayes_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n##############################################################\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"### Predict test data using naive base classifier model ######\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/robertbeaudenon/PycharmProjects/StackOverflow-Quality-Predictor/pyspark/utility.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0msystem_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n AFTER CALL TO FUNCTION'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/robertbeaudenon/PycharmProjects/StackOverflow-Quality-Predictor/pyspark/functions.py\u001b[0m in \u001b[0;36mtrain_naive_bayes_model\u001b[0;34m(cv, data)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_naive_bayes_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/robertbeaudenon/opt/anaconda3/envs/bigdata-lab/lib/python3.5/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/Users/robertbeaudenon/opt/anaconda3/envs/bigdata-lab/lib/python3.5/site-packages/pyspark/ml/tuning.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parallelFitTasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubModel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnFolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/robertbeaudenon/opt/anaconda3/envs/bigdata-lab/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/robertbeaudenon/opt/anaconda3/envs/bigdata-lab/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-consistency",
   "metadata": {},
   "source": [
    "# Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "included-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(fun):\n",
    "    \n",
    "    def wrapper(*args, **kwargs):\n",
    "        print('BEFORE CALL TO FUNCTION')\n",
    "        system_info()\n",
    "        start = time()\n",
    "        rv = fun(*args, **kwargs)\n",
    "        duration = time() - start\n",
    "        print('\\n\\n AFTER CALL TO FUNCTION')\n",
    "        system_info()\n",
    "#         process_info()\n",
    "        print(\"Execution Time: {}\".format(duration))\n",
    "        return rv\n",
    "    \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "amber-barrel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_info():\n",
    "    info = {\n",
    "#         \"Uptime\": timedelta(seconds=time()-psu.boot_time()),\n",
    "        \"CPU in use\": \"{:.2f}%\".format(psu.cpu_percent(interval=.1)),\n",
    "        \"Time on CPU\": timedelta(seconds=psu.cpu_times().system+psu.cpu_times().user),\n",
    "        \"Memory in use\": \"{:.2f}GiB\".format(psu.virtual_memory().available/(1024**3)),\n",
    "        \"Disk in use\": \"{:.2f}%\".format(psu.disk_usage('/').percent),\n",
    "        \"Disk free\": \"{:.2f}GiB\".format(psu.disk_usage('/').free/(1024**3)),    \n",
    "    }\n",
    "    \n",
    "    print(\"\\n\\n SYSTEM INFO\\n\\n\" + \"\\n\".join([\"{}: {}\".format(key,value) for key,value in info.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "raising-confirmation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " SYSTEMINFO\n",
      "\n",
      "CPU in use: 15.0%\n",
      "Uptime: 19:15:26.625819\n",
      "Disk in use: 65.5%\n",
      "Memory in use: 6.625919342041016MiB\n",
      "Dsik free: 5.499961853027344MiB\n",
      "Time on CPU: 7:32:57.350000\n"
     ]
    }
   ],
   "source": [
    "system_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "gentle-motion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:15:19.796094\n"
     ]
    }
   ],
   "source": [
    "print(timedelta(seconds=time()-psu.boot_time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "complimentary-setting",
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds=time()-psu.boot_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "mysterious-croatia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "final-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_info():\n",
    "    for process in psu.process_iter(attrs=('name','cmdline','pid','create_time','cpu_percent','cpu_times','num_threads','memory_percent')):\n",
    "        if \"python\" in process.info[\"name\"]:\n",
    "            mem = process.info['memory_percent']\n",
    "            info = {\n",
    "                \"PID\": process.info[\"pid\"],\n",
    "                \"Create time\": datetime.fromtimestamp(process.create_time()).strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"Uptime\": timedelta(seconds=time() - process.info[\"create_time\"]),\n",
    "                \"CPU in use\": \"{:.2f}%\".format(process.info['cpu_percent']),\n",
    "                \"Time on CPU\": timedelta(seconds=process.info[\"cpu_times\"].system + process.info[\"cpu_times\"].user),\n",
    "                \"Nb of threads\": process.info[\"num_threads\"],\n",
    "                \"Memory in use\": \"{:.2f}%\".format(mem),\n",
    "                \"Memory_usage\": \"{:.2f} GiB\".format(psu.virtual_memory().total*(mem/100)/(1024**3)),\n",
    "            }\n",
    "            \n",
    "            print(\"\\n\\n PROCESS INFO\\n\\n\" + \"\\n\".join([\"{}: {}\".format(key,value) for key,value in info.items()]))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "parental-italic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " PROCESS INFO\n",
      "\n",
      "Uptime: 12:13:20.380172\n",
      "Create time: 2021-04-10 23:46:55\n",
      "Nb of threads: 4\n",
      "Memory_usage: 0.03 GiB\n",
      "Memory in use: 0.16%\n",
      "CPU in use: 0.20%\n",
      "PID: 5065\n",
      "Time on CPU: 0:00:06.343331\n",
      "\n",
      "\n",
      " PROCESS INFO\n",
      "\n",
      "Uptime: 12:13:05.514102\n",
      "Create time: 2021-04-10 23:47:10\n",
      "Nb of threads: 10\n",
      "Memory_usage: 0.03 GiB\n",
      "Memory in use: 0.18%\n",
      "CPU in use: 0.20%\n",
      "PID: 5078\n",
      "Time on CPU: 0:00:03.614826\n",
      "\n",
      "\n",
      " PROCESS INFO\n",
      "\n",
      "Uptime: 12:12:23.593419\n",
      "Create time: 2021-04-10 23:47:52\n",
      "Nb of threads: 1\n",
      "Memory_usage: 0.00 GiB\n",
      "Memory in use: 0.00%\n",
      "CPU in use: 0.00%\n",
      "PID: 5095\n",
      "Time on CPU: 0:00:00.970705\n"
     ]
    }
   ],
   "source": [
    "process_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-occupation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
